{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Assignment Code: DA-AG-013\n",
        "\n",
        "#**SVM & Naive Bayes | Assignment**\n",
        "\n",
        "#Question-1 What is a Support Vector Machine (SVM), and how does it work?\n",
        "- A suport vector machine(SVM) is an machine learning algorithm mostly used for classification but it can also do regression.\n",
        "- the main idea of this is to make groups and classify.\n",
        "- it can be used for face detection ,handwriting detection.\n",
        "\n",
        "- **how does it work:-**\n",
        "  1. Finds the best boundary (hyperplane) to separate classes.\n",
        "  2. Maximizes the margin between closest data points (support vectors).\n",
        "  3. Uses only support vectors to define the decision boundary.\n",
        "  4. Handles non-linear data using kernel functions.\n",
        "  5. Allows some misclassification using soft margins.\n",
        "  6. Controlled by a regularization parameter (C) to balance margin and error.\n",
        "\n",
        "- **Advantages of SVM**\n",
        "  - Great for data with a clear margin between classes.\n",
        "  - Works well even when the number of features is large.\n",
        "  - Only the important data points (support vectors) are used, making efficient in memory.\n",
        "\n",
        "- **Limitations of SVM**\n",
        "  - Can be slow to train on very large datasets.\n",
        "  - Doesn’t perform well when classes are very mixed or overlapping.\n",
        "  - Choosing the right kernel and parameters can be tricky and requires tuning.  \n"
      ],
      "metadata": {
        "id": "xrdmFlRE6N-f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# question-2 Explain the difference between Hard Margin and Soft Margin SVM.\n",
        "- difference between hard margin and soft margin is wirtten below:-\n",
        "\n",
        "# **Hard Margin SVM**\n",
        "\n",
        "- It tries to draw a line that perfectly separates the two classes.\n",
        "- No mistakesare allowed — every point must be on the correct side.\n",
        "- Works only when the data is **perfectly separated** with no overlap.\n",
        "- Not good for real-world data with noise or errors.\n",
        "- Even a small error or outlier can mess up the model.\n",
        "- Not very useful for real-world problems, where data is often noisy or overlapping.\n",
        "\n",
        "\n",
        "# **Soft Margin SVM**\n",
        "\n",
        "-  It allows **some mistakes** to make the model more flexible.\n",
        "-  Tries to balance between separating the data and allowing a few errors.\n",
        "- Works well with **real-world data** that’s messy or has some overlap.\n",
        "- More practical and commonly used than hard margin.\n",
        "- Tries to balance between having a wide margin and making fewer errors.\n",
        "- Works well with data that is not perfectly separable, which is common in most practical situations.\n",
        "\n"
      ],
      "metadata": {
        "id": "SUrpSlm486ip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question-3 What is the Kernel Trick in SVM? Give one example of a kernel and explain its use case.\n",
        "- kernel trick is a trick used in SVM used when a normal straight line can't seperate  the data by changing the way it sees the data by seeing data in upper dimensions where a straight line can seperate the data.\n",
        "- example:-\n",
        "   - This kernel helps when the data is curvy or circular and can't be split with a straight line.\n",
        "   - It’s like drawing a circle around points instead of a line.\n",
        "   - Commonly used in image recognition or handwriting detection, where data patterns are complex.\n",
        "\n",
        "- use cases:-\n",
        "   - 1) handwriting recogition\n",
        "   - 2) face detection\n",
        "   - 3) E-mail spam detection\n",
        "   - 4) fraud detection\n",
        "   - 5) image classification\n",
        "   - 6) Speech recognition"
      ],
      "metadata": {
        "id": "9LcwzEavIK07"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question-4 What is a Naïve Bayes Classifier, and why is it called “naïve”?\n",
        "- The Naïve Bayes Classifier is a machine learning algorithm used for classification tasks — like sorting emails into spam or not spam.\n",
        "- It’s based on Bayes' Theorem, which calculates the probability of something happening given some known facts.\n",
        "- it is developed by thomas bayes in nearly 1700\n",
        "- formula:-\n",
        "\n",
        "$$\n",
        "P(C \\mid x_1, x_2, ..., x_n) = \\frac{P(C) \\cdot P(x_1 \\mid C) \\cdot P(x_2 \\mid C) \\cdot \\ldots \\cdot P(x_n \\mid C)}{P(x_1, x_2, ..., x_n)}\n",
        "$$\n",
        "\n",
        "- it is called naive becuase it assumes that every featire  is indipendent in natuure as it has nothing to do with other data.\n",
        "- its use cases:-\n",
        "  - spam detection\n",
        "  - fraus E-maiil detection\n"
      ],
      "metadata": {
        "id": "XwJnz4z9KqaP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question-5 Describe the Gaussian, Multinomial, and Bernoulli Naïve Bayes variants.When would you use each one?\n",
        "- 1. Gaussian Naïve Bayes:\n",
        " - o Used when features follow a normal (Gaussian) distribution.\n",
        "  - o Example: Predicting if a person has a disease based on body temperature.\n",
        "- 2. Multinomial Naïve Bayes:\n",
        " - o Used for text classification (word frequencies).\n",
        " - o Example: Spam email detection, news categorization.\n",
        "- 3. Bernoulli Naïve Bayes:\n",
        " - o Used when features are binary (0 or 1).\n",
        " - o Example: Sentiment analysis (positive or negative review).\n",
        "\n",
        "- when we will use each one:-\n",
        " - gaussian Naïve Bayes:- Medical diagnosis\n",
        " - Multinomial Naïve Bayes:- spam detection,news article classification\n",
        " - Bernoulli Naïve Bayes:- spam filtering"
      ],
      "metadata": {
        "id": "3mC-efucMQcw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Info:\n",
        " - You can use any suitable datasets like **Iris,** **Breast Cancer**, or  **Wine** from\n",
        "**sklearn.datasets** or a CSV file you have.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FQb6iE34ODKU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question-6 Write a Python program to:\n",
        " - Load the Iris dataset\n",
        " -  Train an SVM Classifier with a linear kernel\n",
        " -  Print the model's accuracy and support vectors."
      ],
      "metadata": {
        "id": "Hsir216iOqWg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OAEquf-a6KT-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71eca159-9d96-4d45-dac5-9956553a0ccf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.00\n",
            "Support Vectors:\n",
            "[[5.1 3.3 1.7 0.5]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [7.2 3.  5.8 1.6]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Labels\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11)\n",
        "\n",
        "# train data\n",
        "model = SVC(kernel='linear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "# doing accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "# printing the output\n",
        "print(\"Support Vectors:\")\n",
        "print(model.support_vectors_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question-7Write a Python program to:\n",
        " -  Load the Breast Cancer dataset\n",
        " -  Train a Gaussian Naïve Bayes model\n",
        " - Print its classification report including precision, recall, and F1-score.\n"
      ],
      "metadata": {
        "id": "dnmdTQo6P-5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11)\n",
        "\n",
        "# train model\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=data.target_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wjqoxD5Poev",
        "outputId": "57543faf-bdfe-4740-f98e-bc8f5695e142"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   malignant       0.97      0.84      0.90        38\n",
            "      benign       0.93      0.99      0.96        76\n",
            "\n",
            "    accuracy                           0.94       114\n",
            "   macro avg       0.95      0.91      0.93       114\n",
            "weighted avg       0.94      0.94      0.94       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question- 8Write a Python program to:\n",
        " - Train an SVM Classifier on the Wine dataset using GridSearchCV to find the best **'C'** and **'gamma'**.\n",
        " -  Print the best hyperparameters and accuracy."
      ],
      "metadata": {
        "id": "0Ldnb70wQTp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Wine dataset\n",
        "wine = datasets.load_wine()\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11)\n",
        "svm_model = SVC()\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'gamma': [1, 0.1, 0.01, 0.001],\n",
        "    'kernel': ['rbf']\n",
        "}\n",
        "# performing grid\n",
        "grid = GridSearchCV(svm_model, param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_model = grid.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Print results\n",
        "print(\"Best Hyperparameters:\", grid.best_params_)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p5BqGkvQR2I",
        "outputId": "fb58df07-b8da-41af-e9aa-bdb42004e93a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "Test Accuracy: 0.8055555555555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "203WyBkwR6hS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}